{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da3a3ea-229c-42c7-b64e-e5a7ac10d815",
   "metadata": {},
   "source": [
    "### Preprocess all data in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7112d221-7f31-4001-b42e-687325823b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DYAD06NF_...\n",
      "Success: No NaN values remain in the DataFrame after interpolation.\n",
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD06NF__processed.csv.\n",
      "Processing DYAD10NF_...\n",
      "Success: No NaN values remain in the DataFrame after interpolation.\n",
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD10NF__processed.csv.\n",
      "Processing DYAD11NF_...\n",
      "Success: No NaN values remain in the DataFrame after interpolation.\n",
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD11NF__processed.csv.\n",
      "Processing DYAD14F_...\n",
      "Success: No NaN values remain in the DataFrame after interpolation.\n",
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD14F__processed.csv.\n",
      "Processing DYAD16F_...\n",
      "Success: No NaN values remain in the DataFrame after interpolation.\n",
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD16F__processed.csv.\n",
      "Processing DYAD21NF_...\n",
      "Success: No NaN values remain in the DataFrame after interpolation.\n",
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD21NF__processed.csv.\n",
      "Processing DYAD24NF_...\n",
      "Success: No NaN values remain in the DataFrame after interpolation.\n",
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD24NF__processed.csv.\n",
      "All datasets processed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# List of dataset names\n",
    "dataset_names = [\n",
    "    #\"DYAD02F_\", \"DYAD06F_\", \"DYAD06NF_\", \"DYAD10F_\", \"DYAD10NF_\", \"DYAD11F_\",\n",
    "    #\"DYAD11NF_\", \"DYAD12F_\", \"DYAD12NF_\", \"DYAD14F_\", \"DYAD14NF_\", \"DYAD15F_\",\n",
    "    #\"DYAD15I_\", \"DYAD15NF_\", \"DYAD16F_\", \"DYAD16I_\", \"DYAD16NF_\", \"DYAD18F_\",\n",
    "    #\"DYAD18I_\", \"DYAD18NF_\", \"DYAD21F_\", \"DYAD21NF_\", \"DYAD23F_\", \"DYAD23NF_\",\n",
    "    #\"DYAD24F_\", \"DYAD24NF_\"\n",
    "    \"DYAD06NF_\", \"DYAD10NF_\", \"DYAD11NF_\", \"DYAD14F_\", \"DYAD16F_\", \"DYAD21NF_\", \"DYAD24NF_\"\n",
    "]\n",
    "\n",
    "# Base directories for input and output\n",
    "base_dir = \"/Users/ruzenkakaldenbach/Desktop/Drive/raw_data_adjusted/\"\n",
    "output_dir = \"/Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/\"\n",
    "\n",
    "# Path to scaling file\n",
    "scaling_file_path = \"/Users/ruzenkakaldenbach/Desktop/Drive/DESK_Measurements_ALL_with_scaling.xlsx\"\n",
    "\n",
    "# Load the scaling file\n",
    "PixDistConvert = pd.read_excel(scaling_file_path)\n",
    "\n",
    "# Define the function to calculate unit vectors\n",
    "def unit_vector(vector):\n",
    "    \"\"\"Returns the unit vector of the given vector.\"\"\"\n",
    "    magnitude = np.linalg.norm(vector)  # Compute the magnitude (length) of the vector\n",
    "    if magnitude == 0:  # Avoid division by zero\n",
    "        return np.array([0, 0])  # Return a zero vector if the magnitude is zero\n",
    "    return vector / magnitude  # Normalize the vector by dividing by its magnitude\n",
    "\n",
    "# Define the function to calculate the angle between two unit vectors\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\"Returns the angle in radians between two unit vectors.\"\"\"\n",
    "    # Clip the dot product to avoid numerical errors and compute the angle\n",
    "    return np.arccos(np.clip(np.dot(v1, v2), -1.0, 1.0))\n",
    "\n",
    "# Define the function to process a single dataset\n",
    "def process_dataset(dat_name):\n",
    "    print(f\"Processing {dat_name}...\")\n",
    "\n",
    "    # Load the dataset (e.g., 'DYAD06NF__adjusted.xlsx')\n",
    "    file_path = f\"{base_dir}{dat_name}_adjusted.xlsx\"\n",
    "    dat_raw = pd.read_excel(file_path)\n",
    "\n",
    "    # Extract the scaling factor for the current dataset\n",
    "    scaling_factor = PixDistConvert.loc[PixDistConvert['Group'] == dat_name, 'Conversion 1px to mm'].values[0]\n",
    "\n",
    "    # When initializing DF, explicitly specify the data types for each column. \n",
    "    # This ensures that columns remain in the desired structure even if rows with all NaN values are concatenated.\n",
    "    # The warning arises because Pandas plans to handle all-NaN rows differently in future versions.\n",
    "    # Currently, it excludes all-NaN columns during concatenation for performance reasons. In the future, it will retain them.\n",
    "    DF = pd.DataFrame({\n",
    "        'xrc': pd.Series(dtype=float),\n",
    "        'yrc': pd.Series(dtype=float),\n",
    "        'xrf': pd.Series(dtype=float),\n",
    "        'yrf': pd.Series(dtype=float),\n",
    "        'xbc': pd.Series(dtype=float),\n",
    "        'ybc': pd.Series(dtype=float),\n",
    "        'xbf': pd.Series(dtype=float),\n",
    "        'ybf': pd.Series(dtype=float),\n",
    "        'xyc': pd.Series(dtype=float),\n",
    "        'yyc': pd.Series(dtype=float),\n",
    "        'xyf': pd.Series(dtype=float),\n",
    "        'yyf': pd.Series(dtype=float),\n",
    "        'frame_timestamp': pd.Series(dtype=float)\n",
    "    })\n",
    "\n",
    "    # Create an array with steps of 0.25 seconds until the max timestamp\n",
    "    Seconds_025 = np.arange(0, int(np.max(dat_raw['frame_timestamp'])), 0.25)\n",
    "\n",
    "    # Map the color codes to their prefixes\n",
    "    color_map = {\n",
    "        'r': 'red',  # 'r' is mapped to 'red'\n",
    "        'b': 'blue',  # 'b' is mapped to 'blue'\n",
    "        'y': 'yellow'  # 'y' is mapped to 'yellow'\n",
    "    }\n",
    "\n",
    "    # Loop through each interval in Seconds_025\n",
    "    for sec in Seconds_025:\n",
    "        # Filter data for the current time range [sec, sec+0.25)\n",
    "        dd = dat_raw[(dat_raw['frame_timestamp'] >= sec) & (dat_raw['frame_timestamp'] < sec + 0.25)]\n",
    "\n",
    "        # Initialize a row for the current second\n",
    "        row = {'frame_timestamp': sec}\n",
    "\n",
    "        # Process each color (red, blue, yellow)\n",
    "        for color_code, color_name in color_map.items():\n",
    "            # Extract the data for center and front dots for the current color\n",
    "            datcenter = dd[['x_tr', 'y_tr']][dd['name'].str.contains(f'{color_name}_center')]\n",
    "            datfront = dd[['x_tr', 'y_tr']][dd['name'].str.contains(f'{color_name}_front')]\n",
    "\n",
    "            if len(datcenter) > 0 and len(datfront) > 0:  # If both center and front dots exist\n",
    "                # Calculate the mean x_tr and y_tr coordinates for center and front dots\n",
    "                row[f'x{color_code}c'] = np.mean(datcenter['x_tr'])\n",
    "                row[f'y{color_code}c'] = np.mean(datcenter['y_tr'])\n",
    "                row[f'x{color_code}f'] = np.mean(datfront['x_tr'])\n",
    "                row[f'y{color_code}f'] = np.mean(datfront['y_tr'])\n",
    "\n",
    "        # Append the row to the DataFrame\n",
    "        DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    # Define a function to interpolate missing values in a column\n",
    "    def interpolate_column_by_index(df, column_name):\n",
    "        valid_idx = df.index[~df[column_name].isna()]  # Get indices with valid values\n",
    "        valid_values = df[column_name][~df[column_name].isna()]  # Extract valid values\n",
    "        f = interp1d(valid_idx, valid_values, kind='linear', fill_value='extrapolate')  # Linear interpolation\n",
    "        df[column_name] = f(df.index)  # Apply interpolation to all rows\n",
    "        return df\n",
    "\n",
    "    # Interpolate missing values for all coordinate columns\n",
    "    coordinate_columns = [col for col in DF.columns if col != 'frame_timestamp']\n",
    "    for column in coordinate_columns:\n",
    "        DF = interpolate_column_by_index(DF, column)\n",
    "\n",
    "        # After interpolation step\n",
    "    if DF.isna().any().any():\n",
    "        print(\"Error: Interpolation did not fill all NaN values.\")\n",
    "        print(DF[DF.isna().any(axis=1)])  # Print rows with NaN values\n",
    "        raise ValueError(\"Interpolation failed to fill all missing values.\")\n",
    "    else:\n",
    "        print(\"Success: No NaN values remain in the DataFrame after interpolation.\")\n",
    "\n",
    "    # Calculate distances between dyads (actual distances of center and front dots)\n",
    "    DF['dist_c_rb'] = np.sqrt((DF['xrc'] - DF['xbc'])**2 + (DF['yrc'] - DF['ybc'])**2)\n",
    "    DF['dist_c_ry'] = np.sqrt((DF['xrc'] - DF['xyc'])**2 + (DF['yrc'] - DF['yyc'])**2)\n",
    "    DF['dist_c_by'] = np.sqrt((DF['xbc'] - DF['xyc'])**2 + (DF['ybc'] - DF['yyc'])**2)\n",
    "    \n",
    "    DF['dist_f_rb'] = np.sqrt((DF['xrf'] - DF['xbf'])**2 + (DF['yrf'] - DF['ybf'])**2)\n",
    "    DF['dist_f_ry'] = np.sqrt((DF['xrf'] - DF['xyf'])**2 + (DF['yrf'] - DF['yyf'])**2)\n",
    "    DF['dist_f_by'] = np.sqrt((DF['xbf'] - DF['xyf'])**2 + (DF['ybf'] - DF['yyf'])**2)\n",
    "\n",
    "    # Apply scaling factor to all distance columns\n",
    "    distance_columns = [\n",
    "        'dist_c_rb', 'dist_c_ry', 'dist_c_by',\n",
    "        'dist_f_rb', 'dist_f_ry', 'dist_f_by'\n",
    "    ]\n",
    "    DF[distance_columns] = DF[distance_columns] * scaling_factor\n",
    "\n",
    "    # Check for equal distances and raise warnings\n",
    "    if (DF['dist_c_ry'] == DF['dist_f_ry']).any():\n",
    "        warnings.warn(\"Some rows have equal distances for central and front dots in Red-Yellow dyad (dist_c_ry == dist_f_ry).\")\n",
    "    \n",
    "    if (DF['dist_c_by'] == DF['dist_f_by']).any():\n",
    "        warnings.warn(\"Some rows have equal distances for central and front dots in Blue-Yellow dyad (dist_c_by == dist_f_by).\")\n",
    "    \n",
    "    if (DF['dist_c_rb'] == DF['dist_f_rb']).any():\n",
    "        warnings.warn(\"Some rows have equal distances for central and front dots in Red-Blue dyad (dist_c_rb == dist_f_rb).\")\n",
    "\n",
    "\n",
    "    # Determine whether children are \"facing\" or \"backing\" each other\n",
    "    DF['facing_ry'] = np.where(DF['dist_c_ry'] > DF['dist_f_ry'], 1, 0)\n",
    "    DF['facing_by'] = np.where(DF['dist_c_by'] > DF['dist_f_by'], 1, 0)\n",
    "    DF['facing_rb'] = np.where(DF['dist_c_rb'] > DF['dist_f_rb'], 1, 0)\n",
    "\n",
    "    # Add head orientation vectors based on center and front dots\n",
    "    DF['vect_x_r'] = DF['xrf'] - DF['xrc']  # Horizontal vector for red\n",
    "    DF['vect_y_r'] = DF['yrf'] - DF['yrc']  # Vertical vector for red\n",
    "\n",
    "    DF['vect_x_b'] = DF['xbf'] - DF['xbc']  # Horizontal vector for blue\n",
    "    DF['vect_y_b'] = DF['ybf'] - DF['ybc']  # Vertical vector for blue\n",
    "\n",
    "    DF['vect_x_y'] = DF['xyf'] - DF['xyc']  # Horizontal vector for yellow\n",
    "    DF['vect_y_y'] = DF['yyf'] - DF['yyc']  # Vertical vector for yellow\n",
    "\n",
    "    # Compute unit vectors for red, blue, and yellow\n",
    "    DF['unit_vect_x_r'], DF['unit_vect_y_r'] = zip(*DF.apply(lambda row: unit_vector([row['vect_x_r'], row['vect_y_r']]), axis=1))\n",
    "    DF['unit_vect_x_b'], DF['unit_vect_y_b'] = zip(*DF.apply(lambda row: unit_vector([row['vect_x_b'], row['vect_y_b']]), axis=1))\n",
    "    DF['unit_vect_x_y'], DF['unit_vect_y_y'] = zip(*DF.apply(lambda row: unit_vector([row['vect_x_y'], row['vect_y_y']]), axis=1))\n",
    "\n",
    "    # Compute angles in degrees for each dyad\n",
    "    DF['deg_ry'] = DF.apply(lambda row: np.rad2deg(angle_between(\n",
    "        [row['unit_vect_x_r'], row['unit_vect_y_r']],\n",
    "        [row['unit_vect_x_y'], row['unit_vect_y_y']]\n",
    "    )), axis=1)\n",
    "\n",
    "    DF['deg_rb'] = DF.apply(lambda row: np.rad2deg(angle_between(\n",
    "        [row['unit_vect_x_r'], row['unit_vect_y_r']],\n",
    "        [row['unit_vect_x_b'], row['unit_vect_y_b']]\n",
    "    )), axis=1)\n",
    "\n",
    "    DF['deg_by'] = DF.apply(lambda row: np.rad2deg(angle_between(\n",
    "        [row['unit_vect_x_b'], row['unit_vect_y_b']],\n",
    "        [row['unit_vect_x_y'], row['unit_vect_y_y']]\n",
    "    )), axis=1)\n",
    "\n",
    "    # Save the processed dataset to the specified directory\n",
    "    output_file = f\"{output_dir}Loopy_{dat_name}_processed.csv\"\n",
    "    DF.to_csv(output_file, index=False)\n",
    "    print(f\"Saved processed data to {output_file}.\")\n",
    "\n",
    "# Process all datasets in the list\n",
    "for dataset_name in dataset_names:\n",
    "    process_dataset(dataset_name)\n",
    "\n",
    "print(\"All datasets processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56bf2dfe-858f-49f8-9690-bcde65d31c28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDF\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2853a-79de-4861-9ce8-bfc9edc89904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
