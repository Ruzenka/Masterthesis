{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da3a3ea-229c-42c7-b64e-e5a7ac10d815",
   "metadata": {},
   "source": [
    "### Preprocess all data in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b05315c-22bc-407d-8c85-d63f973a80bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DYAD06NF_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD06NF__preprocessed.csv.\n",
      "Processing DYAD10NF_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD10NF__preprocessed.csv.\n",
      "Processing DYAD11NF_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n",
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD11NF__preprocessed.csv.\n",
      "Processing DYAD14F_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD14F__preprocessed.csv.\n",
      "Processing DYAD16F_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n",
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD16F__preprocessed.csv.\n",
      "Processing DYAD21NF_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD21NF__preprocessed.csv.\n",
      "Processing DYAD24NF_...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m7/mw8cknkx6b58s7sq4mdg8nhc0000gn/T/ipykernel_67226/3984110204.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed data to /Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/Loopy_DYAD24NF__preprocessed.csv.\n",
      "All datasets processed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# List of dataset names\n",
    "dataset_names = [\n",
    "    #\"DYAD02F_\", \"DYAD06F_\", \"DYAD06NF_\", \"DYAD10F_\", \"DYAD10NF_\", \"DYAD11F_\",\n",
    "    #\"DYAD11NF_\", \"DYAD12F_\", \"DYAD12NF_\", \"DYAD14F_\", \"DYAD14NF_\", \"DYAD15F_\",\n",
    "    #\"DYAD15I_\", \"DYAD15NF_\", \"DYAD16F_\", \"DYAD16I_\", \"DYAD16NF_\", \"DYAD18F_\",\n",
    "    #\"DYAD18I_\", \"DYAD18NF_\", \"DYAD21F_\", \"DYAD21NF_\", \"DYAD23F_\", \"DYAD23NF_\",\n",
    "    #\"DYAD24F_\", \"DYAD24NF_\"\n",
    "    \"DYAD06NF_\", \"DYAD10NF_\", \"DYAD11NF_\", \"DYAD14F_\", \"DYAD16F_\", \"DYAD21NF_\", \"DYAD24NF_\"\n",
    "]\n",
    "\n",
    "# Base directories for input and output\n",
    "base_dir = \"/Users/ruzenkakaldenbach/Desktop/Drive/raw_data_adjusted/\"\n",
    "output_dir = \"/Users/ruzenkakaldenbach/Desktop/Drive/Loopy_preprocessed_data/\"\n",
    "\n",
    "# Path to scaling file\n",
    "scaling_file_path = \"/Users/ruzenkakaldenbach/Desktop/Drive/DESK_Measurements_ALL_with_scaling.xlsx\"\n",
    "\n",
    "# Load the scaling file\n",
    "PixDistConvert = pd.read_excel(scaling_file_path)\n",
    "\n",
    "# Define the function to process a single dataset\n",
    "def process_dataset(dat_name):\n",
    "    print(f\"Processing {dat_name}...\")\n",
    "\n",
    "    # Load the dataset (e.g., 'DYAD06NF__adjusted.xlsx')\n",
    "    file_path = f\"{base_dir}{dat_name}_adjusted.xlsx\"\n",
    "    dat_raw = pd.read_excel(file_path)\n",
    "\n",
    "    # Extract the scaling factor for the current dataset\n",
    "    scaling_factor = PixDistConvert.loc[PixDistConvert['Group'] == dat_name, 'Conversion 1px to mm'].values[0]\n",
    "\n",
    "    # Initialize the output DataFrame with necessary columns\n",
    "    DF = pd.DataFrame(columns=['xrc', 'yrc', 'xrf', 'yrf', \n",
    "                               'xbc', 'ybc', 'xbf', 'ybf', \n",
    "                               'xyc', 'yyc', 'xyf', 'yyf', \n",
    "                               'frame_timestamp'])\n",
    "\n",
    "    # Create an array with steps of 0.25 seconds until the max timestamp\n",
    "    Seconds_025 = np.arange(0, int(np.max(dat_raw['frame_timestamp'])), 0.25)\n",
    "\n",
    "    # Map the color codes to their prefixes\n",
    "    color_map = {\n",
    "        'r': 'red',  # 'r' is mapped to 'red'\n",
    "        'b': 'blue',  # 'b' is mapped to 'blue'\n",
    "        'y': 'yellow'  # 'y' is mapped to 'yellow'\n",
    "    }\n",
    "\n",
    "    # Loop through each interval in Seconds_025\n",
    "    for sec in Seconds_025:\n",
    "        # Filter data for the current time range [sec, sec+0.25)\n",
    "        dd = dat_raw[(dat_raw['frame_timestamp'] >= sec) & (dat_raw['frame_timestamp'] < sec + 0.25)]\n",
    "\n",
    "        # Initialize a row for the current second\n",
    "        row = {'frame_timestamp': sec}\n",
    "\n",
    "        # Process each color (red, blue, yellow)\n",
    "        for color_code, color_name in color_map.items():\n",
    "            # Extract the data for center and front dots for the current color\n",
    "            datcenter = dd[['x_tr', 'y_tr']][dd['name'].str.contains(f'{color_name}_center')]\n",
    "            datfront = dd[['x_tr', 'y_tr']][dd['name'].str.contains(f'{color_name}_front')]\n",
    "\n",
    "            if len(datcenter) > 0 and len(datfront) > 0:  # If both center and front dots exist\n",
    "                # Calculate the mean x_tr and y_tr coordinates for center and front dots\n",
    "                row[f'x{color_code}c'] = np.mean(datcenter['x_tr'])\n",
    "                row[f'y{color_code}c'] = np.mean(datcenter['y_tr'])\n",
    "                row[f'x{color_code}f'] = np.mean(datfront['x_tr'])\n",
    "                row[f'y{color_code}f'] = np.mean(datfront['y_tr'])\n",
    "\n",
    "        # Append the row to the DataFrame\n",
    "        DF = pd.concat([DF, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "    # Define a function to interpolate missing values in a column\n",
    "    def interpolate_column_by_index(df, column_name):\n",
    "        valid_idx = df.index[~df[column_name].isna()]  # Get indices with valid values\n",
    "        valid_values = df[column_name][~df[column_name].isna()]  # Extract valid values\n",
    "        f = interp1d(valid_idx, valid_values, kind='linear', fill_value='extrapolate')  # Linear interpolation\n",
    "        df[column_name] = f(df.index)  # Apply interpolation to all rows\n",
    "        return df\n",
    "\n",
    "    # Interpolate missing values for all coordinate columns\n",
    "    coordinate_columns = [col for col in DF.columns if col != 'frame_timestamp']\n",
    "    for column in coordinate_columns:\n",
    "        DF = interpolate_column_by_index(DF, column)\n",
    "\n",
    "    # Calculate distances between dyads (squared distances of center and front dots)\n",
    "    DF['dist_c_rb'] = (DF['xrc'] - DF['xbc'])**2 + (DF['yrc'] - DF['ybc'])**2\n",
    "    DF['dist_c_ry'] = (DF['xrc'] - DF['xyc'])**2 + (DF['yrc'] - DF['yyc'])**2\n",
    "    DF['dist_c_by'] = (DF['xbc'] - DF['xyc'])**2 + (DF['ybc'] - DF['yyc'])**2\n",
    "\n",
    "    DF['dist_f_rb'] = (DF['xrf'] - DF['xbf'])**2 + (DF['yrf'] - DF['ybf'])**2\n",
    "    DF['dist_f_ry'] = (DF['xrf'] - DF['xyf'])**2 + (DF['yrf'] - DF['yyf'])**2\n",
    "    DF['dist_f_by'] = (DF['xbf'] - DF['xyf'])**2 + (DF['ybf'] - DF['yyf'])**2\n",
    "\n",
    "    # Apply scaling factor to all distance columns\n",
    "    distance_columns = [\n",
    "        'dist_c_rb', 'dist_c_ry', 'dist_c_by',\n",
    "        'dist_f_rb', 'dist_f_ry', 'dist_f_by'\n",
    "    ]\n",
    "    DF[distance_columns] = DF[distance_columns] * scaling_factor\n",
    "\n",
    "    # Save the processed dataset to the specified directory\n",
    "    output_file = f\"{output_dir}Loopy_{dat_name}_preprocessed.csv\"\n",
    "    DF.to_csv(output_file, index=False)\n",
    "    print(f\"Saved processed data to {output_file}.\")\n",
    "\n",
    "# Process all datasets in the list\n",
    "for dataset_name in dataset_names:\n",
    "    process_dataset(dataset_name)\n",
    "\n",
    "print(\"All datasets processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb527d42-9261-4c50-9f4c-a4117fd2e37d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
